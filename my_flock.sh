关于forck

flock 是对于整个文件的建议性锁。也就是说，如果一个进程在一个文件（inode）上放了锁，那么其它进程是可以知道的。（建议性锁不强求进程遵守。）最棒的一点是，它的第一个参数是文件描述符，在此文件描述符关闭时，锁会自动释放。而当进程终止时，所有的文件描述符均会被关闭。

应用场景
linux的crontab命令，可以定时执行操作，最小周期是每分钟执行一次。现在有个问题，如果设定了任务每2分钟执行一次，但有可能执行该任务需要花费10分钟，这时系统会再执行任务。导致两个相同的任务在执行。这种情况下可能会出现一些并发问题，严重时会导致出现脏数据/性能瓶颈的恶性循环。
通过使用flock建立排它锁可以规避这个问题，如果一个进程对某个加了排他锁，则其它进程无法加锁，可以选择等待超时或马上返回。

例如
cat /opt/sleep.sh

#!/bin/bash
# Description: test for file flock
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin
export PATH
echo ""
echo "----------------------------------"
echo "start at `date '+%Y-%m-%d %H:%M:%S'` ..."
sleep 600s
echo "finished at `date '+%Y-%m-%d %H:%M:%S'` ..."


设置计划任务每2分钟执行

2/* * * * *  /opt/sleep.sh >> /tmp/sleep.log

而实际情况是10分钟后我们查看进程ps aux|grep sleep.sh 可以看到有5个进程在运行,我们则希望执行完上一任务，再执行下一任务，如果上一任务未执行完成，则这次的任务不执行，直到下一周期再判断，如果上一任务执行完成，则可以执行下一任务。
改进方法
我们可以使用一个锁文件，来记录任务是否执行中。
首先判断/tmp/sleep.lock是否存在，如果不存在，则创建，然后执行任务，任务执行完后删除锁文件。如果锁文件已经存在，则退出这次的任务。这样的确可以保证任务执行其间不会有新任务执行，但这样需要在任务文件中写代码做判断，不方便。能不能把任务锁定的判断放在任务以外呢？
使用linux flock 文件锁实现任务锁定，解决冲突
格式
flock [-sxun][-w #]
flock [-sxon][-w #] file [-c] command

选项
-s, --shared:    获得一个共享锁
-x, --exclusive: 获得一个独占锁/排他锁
-u, --unlock:    移除一个锁，通常是不需要的，脚本执行完会自动丢弃锁
-n, --nonblock:  如果没有立即获得锁，直接失败而不是等待
-w, --timeout:   如果没有立即获得锁，等待指定时间
-o, --close:     在运行命令前关闭文件的描述符号。用于如果命令产生子进程时会不受锁的管控
-c, --command:   在shell中运行一个单独的命令
-h, --help       显示帮助
-V, --version:   显示版本
-w 等待时间,秒

独占锁/排他锁

设置锁
使用计划任务执行sleep.sh，文件锁使用独占锁，如果锁定则失败不等待。这样当任务未执行完成，下一任务判断到/tmp/mytest.lock被锁定，则结束当前的任务，下一周期再判断。参数为-xn

2/* * * * * flock -xn /tmp/sleep.lock -c /opt/sleep.sh >> /tmp/sleep.log


创建独占锁/排他锁，加上等待超时/秒
启动的定时任务等待了20秒后，上一个任务释放了锁，任务可以马上拿到锁，并继续执行

2/* * * * * flock -x -w 20 /tmp/sleep.lock -c /opt/sleep.sh >> /tmp/sleep.log
